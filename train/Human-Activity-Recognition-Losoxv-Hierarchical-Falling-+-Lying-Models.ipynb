{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72042606-f3b8-4869-8cbd-c045984ff1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tsfresh\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64847742-8bef-4894-8fde-624d9483aa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# keras goodies\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Conv1D, Dropout, MaxPooling1D, BatchNormalization\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import metrics as kmetrics\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12eba315",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import ConvLSTM2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41ff02ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/afs/inf.ed.ac.uk/user/s18/s1894401/PDIoT/Practical/Kai_Respeck_data/Climbing_stairs.csv',\n",
       " '/afs/inf.ed.ac.uk/user/s18/s1894401/PDIoT/Practical/Kai_Respeck_data/Descending_stairs.csv',\n",
       " '/afs/inf.ed.ac.uk/user/s18/s1894401/PDIoT/Practical/Kai_Respeck_data/Desk_work.csv',\n",
       " '/afs/inf.ed.ac.uk/user/s18/s1894401/PDIoT/Practical/Kai_Respeck_data/Falling_on_the_back.csv',\n",
       " '/afs/inf.ed.ac.uk/user/s18/s1894401/PDIoT/Practical/Kai_Respeck_data/Falling_on_the_knees.csv',\n",
       " '/afs/inf.ed.ac.uk/user/s18/s1894401/PDIoT/Practical/Kai_Respeck_data/Falling_on_the_left.csv',\n",
       " '/afs/inf.ed.ac.uk/user/s18/s1894401/PDIoT/Practical/Kai_Respeck_data/Falling_on_the_right.csv',\n",
       " '/afs/inf.ed.ac.uk/user/s18/s1894401/PDIoT/Practical/Kai_Respeck_data/Lying_down_left.csv',\n",
       " '/afs/inf.ed.ac.uk/user/s18/s1894401/PDIoT/Practical/Kai_Respeck_data/Lying_down_on_back.csv',\n",
       " '/afs/inf.ed.ac.uk/user/s18/s1894401/PDIoT/Practical/Kai_Respeck_data/Lying_down_on_right.csv',\n",
       " '/afs/inf.ed.ac.uk/user/s18/s1894401/PDIoT/Practical/Kai_Respeck_data/Lying_down_on_stomach.csv',\n",
       " '/afs/inf.ed.ac.uk/user/s18/s1894401/PDIoT/Practical/Kai_Respeck_data/Running.csv',\n",
       " '/afs/inf.ed.ac.uk/user/s18/s1894401/PDIoT/Practical/Kai_Respeck_data/Sitting.csv',\n",
       " '/afs/inf.ed.ac.uk/user/s18/s1894401/PDIoT/Practical/Kai_Respeck_data/Sitting_bent_backward.csv',\n",
       " '/afs/inf.ed.ac.uk/user/s18/s1894401/PDIoT/Practical/Kai_Respeck_data/Sitting_bent_forward.csv',\n",
       " '/afs/inf.ed.ac.uk/user/s18/s1894401/PDIoT/Practical/Kai_Respeck_data/Standing.csv',\n",
       " '/afs/inf.ed.ac.uk/user/s18/s1894401/PDIoT/Practical/Kai_Respeck_data/Walking_at_normal_speed.csv'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_directory = os.path.join(os.getcwd(), 'Kai_Respeck_data')\n",
    "filenames = []\n",
    "\n",
    "for root, _, files in os.walk(data_directory, topdown=False):\n",
    "    for name in files:\n",
    "        filenames.append(os.path.join(root, name))\n",
    "\n",
    "set(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a16e7623",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = []\n",
    "for filename in filenames:\n",
    "    dataframes.append(pd.read_csv(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93d214db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>accel_x</th>\n",
       "      <th>accel_y</th>\n",
       "      <th>accel_z</th>\n",
       "      <th>gyro_x</th>\n",
       "      <th>gyro_y</th>\n",
       "      <th>gyro_z</th>\n",
       "      <th>sensor_type</th>\n",
       "      <th>activity_type</th>\n",
       "      <th>activity_code</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>notes</th>\n",
       "      <th>recording_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1632922547206</td>\n",
       "      <td>0.015137</td>\n",
       "      <td>-0.638733</td>\n",
       "      <td>-0.106506</td>\n",
       "      <td>6.609375</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3.171875</td>\n",
       "      <td>Respeck</td>\n",
       "      <td>Climbing stairs</td>\n",
       "      <td>12</td>\n",
       "      <td>s1800883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Respeck_s1800883_Climbing stairs_29-09-2021_14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1632922547235</td>\n",
       "      <td>0.036621</td>\n",
       "      <td>-0.818176</td>\n",
       "      <td>-0.220764</td>\n",
       "      <td>3.687500</td>\n",
       "      <td>-4.812500</td>\n",
       "      <td>1.453125</td>\n",
       "      <td>Respeck</td>\n",
       "      <td>Climbing stairs</td>\n",
       "      <td>12</td>\n",
       "      <td>s1800883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Respeck_s1800883_Climbing stairs_29-09-2021_14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1632922547281</td>\n",
       "      <td>-0.022949</td>\n",
       "      <td>-1.087952</td>\n",
       "      <td>-0.211731</td>\n",
       "      <td>-1.609375</td>\n",
       "      <td>-5.156250</td>\n",
       "      <td>-10.078125</td>\n",
       "      <td>Respeck</td>\n",
       "      <td>Climbing stairs</td>\n",
       "      <td>12</td>\n",
       "      <td>s1800883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Respeck_s1800883_Climbing stairs_29-09-2021_14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1632922547327</td>\n",
       "      <td>0.006592</td>\n",
       "      <td>-1.313293</td>\n",
       "      <td>-0.159973</td>\n",
       "      <td>-8.921875</td>\n",
       "      <td>-0.218750</td>\n",
       "      <td>-11.781250</td>\n",
       "      <td>Respeck</td>\n",
       "      <td>Climbing stairs</td>\n",
       "      <td>12</td>\n",
       "      <td>s1800883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Respeck_s1800883_Climbing stairs_29-09-2021_14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1632922547356</td>\n",
       "      <td>0.017090</td>\n",
       "      <td>-1.298401</td>\n",
       "      <td>-0.305969</td>\n",
       "      <td>-19.750000</td>\n",
       "      <td>-6.578125</td>\n",
       "      <td>-5.171875</td>\n",
       "      <td>Respeck</td>\n",
       "      <td>Climbing stairs</td>\n",
       "      <td>12</td>\n",
       "      <td>s1800883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Respeck_s1800883_Climbing stairs_29-09-2021_14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12925</th>\n",
       "      <td>1632919138876</td>\n",
       "      <td>0.109863</td>\n",
       "      <td>0.042908</td>\n",
       "      <td>-0.953674</td>\n",
       "      <td>-0.453125</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>Respeck</td>\n",
       "      <td>Lying down on stomach</td>\n",
       "      <td>8</td>\n",
       "      <td>s1800883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Respeck_s1800883_Lying down on stomach_29-09-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12926</th>\n",
       "      <td>1632919138907</td>\n",
       "      <td>0.110596</td>\n",
       "      <td>0.035583</td>\n",
       "      <td>-0.950012</td>\n",
       "      <td>-0.328125</td>\n",
       "      <td>0.078125</td>\n",
       "      <td>0.484375</td>\n",
       "      <td>Respeck</td>\n",
       "      <td>Lying down on stomach</td>\n",
       "      <td>8</td>\n",
       "      <td>s1800883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Respeck_s1800883_Lying down on stomach_29-09-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12927</th>\n",
       "      <td>1632919138952</td>\n",
       "      <td>0.110352</td>\n",
       "      <td>0.041199</td>\n",
       "      <td>-0.953186</td>\n",
       "      <td>-0.421875</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.296875</td>\n",
       "      <td>Respeck</td>\n",
       "      <td>Lying down on stomach</td>\n",
       "      <td>8</td>\n",
       "      <td>s1800883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Respeck_s1800883_Lying down on stomach_29-09-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12928</th>\n",
       "      <td>1632919138998</td>\n",
       "      <td>0.110107</td>\n",
       "      <td>0.038025</td>\n",
       "      <td>-0.954163</td>\n",
       "      <td>-0.437500</td>\n",
       "      <td>-0.140625</td>\n",
       "      <td>0.406250</td>\n",
       "      <td>Respeck</td>\n",
       "      <td>Lying down on stomach</td>\n",
       "      <td>8</td>\n",
       "      <td>s1800883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Respeck_s1800883_Lying down on stomach_29-09-2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12929</th>\n",
       "      <td>1632919139026</td>\n",
       "      <td>0.111084</td>\n",
       "      <td>0.043152</td>\n",
       "      <td>-0.950012</td>\n",
       "      <td>-0.421875</td>\n",
       "      <td>-0.015625</td>\n",
       "      <td>0.453125</td>\n",
       "      <td>Respeck</td>\n",
       "      <td>Lying down on stomach</td>\n",
       "      <td>8</td>\n",
       "      <td>s1800883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Respeck_s1800883_Lying down on stomach_29-09-2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12930 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           timestamp   accel_x   accel_y   accel_z     gyro_x    gyro_y  \\\n",
       "0      1632922547206  0.015137 -0.638733 -0.106506   6.609375  2.500000   \n",
       "1      1632922547235  0.036621 -0.818176 -0.220764   3.687500 -4.812500   \n",
       "2      1632922547281 -0.022949 -1.087952 -0.211731  -1.609375 -5.156250   \n",
       "3      1632922547327  0.006592 -1.313293 -0.159973  -8.921875 -0.218750   \n",
       "4      1632922547356  0.017090 -1.298401 -0.305969 -19.750000 -6.578125   \n",
       "...              ...       ...       ...       ...        ...       ...   \n",
       "12925  1632919138876  0.109863  0.042908 -0.953674  -0.453125  0.171875   \n",
       "12926  1632919138907  0.110596  0.035583 -0.950012  -0.328125  0.078125   \n",
       "12927  1632919138952  0.110352  0.041199 -0.953186  -0.421875  0.046875   \n",
       "12928  1632919138998  0.110107  0.038025 -0.954163  -0.437500 -0.140625   \n",
       "12929  1632919139026  0.111084  0.043152 -0.950012  -0.421875 -0.015625   \n",
       "\n",
       "          gyro_z sensor_type          activity_type  activity_code subject_id  \\\n",
       "0       3.171875     Respeck        Climbing stairs             12   s1800883   \n",
       "1       1.453125     Respeck        Climbing stairs             12   s1800883   \n",
       "2     -10.078125     Respeck        Climbing stairs             12   s1800883   \n",
       "3     -11.781250     Respeck        Climbing stairs             12   s1800883   \n",
       "4      -5.171875     Respeck        Climbing stairs             12   s1800883   \n",
       "...          ...         ...                    ...            ...        ...   \n",
       "12925   0.421875     Respeck  Lying down on stomach              8   s1800883   \n",
       "12926   0.484375     Respeck  Lying down on stomach              8   s1800883   \n",
       "12927   0.296875     Respeck  Lying down on stomach              8   s1800883   \n",
       "12928   0.406250     Respeck  Lying down on stomach              8   s1800883   \n",
       "12929   0.453125     Respeck  Lying down on stomach              8   s1800883   \n",
       "\n",
       "       notes                                       recording_id  \n",
       "0        NaN  Respeck_s1800883_Climbing stairs_29-09-2021_14...  \n",
       "1        NaN  Respeck_s1800883_Climbing stairs_29-09-2021_14...  \n",
       "2        NaN  Respeck_s1800883_Climbing stairs_29-09-2021_14...  \n",
       "3        NaN  Respeck_s1800883_Climbing stairs_29-09-2021_14...  \n",
       "4        NaN  Respeck_s1800883_Climbing stairs_29-09-2021_14...  \n",
       "...      ...                                                ...  \n",
       "12925    NaN  Respeck_s1800883_Lying down on stomach_29-09-2...  \n",
       "12926    NaN  Respeck_s1800883_Lying down on stomach_29-09-2...  \n",
       "12927    NaN  Respeck_s1800883_Lying down on stomach_29-09-2...  \n",
       "12928    NaN  Respeck_s1800883_Lying down on stomach_29-09-2...  \n",
       "12929    NaN  Respeck_s1800883_Lying down on stomach_29-09-2...  \n",
       "\n",
       "[12930 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Kai_df = pd.concat(dataframes).reset_index(drop=True)\n",
    "Kai_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2abacbfb-9269-4bc0-bc4e-6631c453f065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/inf.ed.ac.uk/user/s18/s1894401/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "base_df = pd.read_csv('Respeck_recordings_clean.csv')\n",
    "movement_indices = np.asarray(base_df[base_df.activity_type == 'Movement'].index) # drop general movement\n",
    "base_df.drop(movement_indices, inplace=True)\n",
    "base_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09913fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning data\n",
    "df_respeck = base_df[(base_df['activity_type']=='Standing') & (base_df['accel_y'] < -0.5)]\n",
    "df_respeck = pd.concat([df_respeck, base_df[(base_df['activity_type']=='Walking at normal speed') & (base_df['accel_y'] < 0.5)]])\n",
    "df_respeck = pd.concat([df_respeck, base_df[(base_df['activity_type']=='Climbing stairs') & (base_df['accel_y'] < 0)]])\n",
    "df_respeck = pd.concat([df_respeck, base_df[(base_df['activity_type']=='Desk work') & (base_df['accel_y'] < -0.5)]])\n",
    "df_respeck = pd.concat([df_respeck, base_df[(base_df['activity_type']=='Sitting') & (base_df['accel_y'] < -0.5)]])\n",
    "df_respeck = pd.concat([df_respeck, base_df[(base_df['activity_type']=='Sitting bent forward') & (base_df['accel_y'] < -0.25)]])\n",
    "df_respeck = pd.concat([df_respeck, base_df[(base_df['activity_type']=='Sitting bent backward') & (base_df['accel_y'] < 0)]])\n",
    "df_respeck = pd.concat([df_respeck, base_df[(base_df['activity_type']=='Lying down on back')]])\n",
    "df_respeck = pd.concat([df_respeck, base_df[(base_df['activity_type']=='Lying down on stomach')]])\n",
    "df_respeck = pd.concat([df_respeck, base_df[(base_df['activity_type']=='Lying down left')]])\n",
    "df_respeck = pd.concat([df_respeck, base_df[(base_df['activity_type']=='Lying down right')]])\n",
    "df_respeck = pd.concat([df_respeck, base_df[(base_df['activity_type']=='Falling on the left')]])\n",
    "df_respeck = pd.concat([df_respeck, base_df[(base_df['activity_type']=='Falling on the right')]])\n",
    "df_respeck = pd.concat([df_respeck, base_df[(base_df['activity_type']=='Falling on knees')]])\n",
    "df_respeck = pd.concat([df_respeck, base_df[(base_df['activity_type']=='Falling on the back')]])\n",
    "df_respeck = pd.concat([df_respeck, base_df[(base_df['activity_type']=='Running')]])\n",
    "base_df = pd.concat([df_respeck, base_df[(base_df['activity_type']=='Descending stairs') & (base_df['accel_x'] > -0.5) & (base_df['accel_y'] < 0.5)]])\n",
    "base_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "390365f5-faf5-4210-a643-5b8b2833e570",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest = ['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0d05ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "falling_dfs = []\n",
    "for _ in range(10):\n",
    "    falling_dfs.append(base_df[base_df.activity_type == 'Falling on knees'])\n",
    "    falling_dfs.append(base_df[base_df.activity_type == 'Falling on the right'])\n",
    "    falling_dfs.append(base_df[base_df.activity_type == 'Falling on the left'])\n",
    "    falling_dfs.append(base_df[base_df.activity_type == 'Falling on the back'])\n",
    "\n",
    "falling_df = pd.concat(falling_dfs).reset_index(drop=True) # oversample for falling\n",
    "\n",
    "running_dfs = []\n",
    "for _ in range(2):\n",
    "    running_dfs.append(base_df[base_df.activity_type == 'Running']) \n",
    "\n",
    "running_df = pd.concat(running_dfs).reset_index(drop=True) # oversample for running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1d542d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df = pd.concat([base_df, falling_df, running_df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f57d831-a18f-4177-ab38-6642ea150600",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_indices = set()\n",
    "for i in range(len(base_df)):\n",
    "    for col in columns_of_interest:\n",
    "        if pd.isnull(base_df.loc[i, col]):\n",
    "            nan_indices.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4e406b7-a4c3-4ea2-8311-ad87ad37c9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df.drop(list(nan_indices), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c80f1d2e-23ac-4bdb-b8c9-8b7b0281eefb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_dataframes = []\n",
    "for rid, group in base_df.groupby(\"subject_id\"):\n",
    "    subject_dataframes.append(group)\n",
    "n = len(subject_dataframes)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99e3d171",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/afs/inf.ed.ac.uk/user/s18/s1894401/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1597: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n",
      "/afs/inf.ed.ac.uk/user/s18/s1894401/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1720: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value, pi)\n"
     ]
    }
   ],
   "source": [
    "# Get the final sliding windows for the whole dataset\n",
    "\n",
    "window_size = 50 # 50 datapoints for the window size, which, at 25Hz, means 2 seconds\n",
    "step_size = 25 # this is 50% overlap\n",
    "\n",
    "window_number = 0 # start a counter at 0 to keep track of the window number\n",
    "\n",
    "all_overlapping_windows = []\n",
    "\n",
    "for rid, group in base_df.groupby(\"recording_id\"):\n",
    "    # print(f\"Processing rid = {rid}\")\n",
    "    \n",
    "    large_enough_windows = [window for window in group.rolling(window=window_size, min_periods=window_size) if len(window) == window_size]\n",
    "    \n",
    "    overlapping_windows = large_enough_windows[::step_size] \n",
    "    \n",
    "    # then we will append a window ID to each window\n",
    "    for window in overlapping_windows:\n",
    "        window.loc[:, 'window_id'] = window_number\n",
    "        window_number += 1\n",
    "    \n",
    "    if len(overlapping_windows) == 0:\n",
    "            continue\n",
    "    \n",
    "    all_overlapping_windows.append(pd.concat(overlapping_windows).reset_index(drop=True))\n",
    "\n",
    "\n",
    "final_sliding_windows = pd.concat(all_overlapping_windows).reset_index(drop=True)\n",
    "subject_ids = list(set(base_df['subject_id']))\n",
    "training_partitions = [final_sliding_windows[final_sliding_windows.subject_id != s] for s in subject_ids]\n",
    "testing_partitions = [final_sliding_windows[final_sliding_windows.subject_id == s] for s in subject_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8282a6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the final sliding windows for Kai's dataset\n",
    "\n",
    "window_size = 50 # 50 datapoints for the window size, which, at 25Hz, means 2 seconds\n",
    "step_size = 25 # this is 50% overlap\n",
    "\n",
    "window_number = 0 # start a counter at 0 to keep track of the window number\n",
    "\n",
    "all_overlapping_windows = []\n",
    "\n",
    "for rid, group in Kai_df.groupby(\"recording_id\"):\n",
    "    # print(f\"Processing rid = {rid}\")\n",
    "    \n",
    "    large_enough_windows = [window for window in group.rolling(window=window_size, min_periods=window_size) if len(window) == window_size]\n",
    "    \n",
    "    overlapping_windows = large_enough_windows[::step_size] \n",
    "    \n",
    "    # then we will append a window ID to each window\n",
    "    for window in overlapping_windows:\n",
    "        window.loc[:, 'window_id'] = window_number\n",
    "        window_number += 1\n",
    "    \n",
    "    if len(overlapping_windows) == 0:\n",
    "            continue\n",
    "    \n",
    "    all_overlapping_windows.append(pd.concat(overlapping_windows).reset_index(drop=True))\n",
    "\n",
    "\n",
    "Kai_final_sliding_windows = pd.concat(all_overlapping_windows).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f89e57cb-65bb-4b22-91a1-1f6aea6fec59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data was collected using the sensors: ['Respeck']\n",
      "The data was collected for the activities: ['Standing' 'Walking at normal speed' 'Climbing stairs' 'Desk work'\n",
      " 'Sitting' 'Sitting bent forward' 'Sitting bent backward'\n",
      " 'Lying down on back' 'Lying down on stomach' 'Lying down left'\n",
      " 'Lying down right' 'Falling on the left' 'Falling on the right'\n",
      " 'Falling on knees' 'Falling on the back' 'Running' 'Descending stairs']\n",
      "The number of unique recordings is: 809\n",
      "The subject IDs in the recordings are: 46\n"
     ]
    }
   ],
   "source": [
    "print(f\"The data was collected using the sensors: {base_df.sensor_type.unique()}\")\n",
    "print(f\"The data was collected for the activities: {base_df.activity_type.unique()}\")\n",
    "print(f\"The number of unique recordings is: {len(base_df.recording_id.unique())}\")\n",
    "print(f\"The subject IDs in the recordings are: {len(base_df.subject_id.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85e0ad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_class_labels = {\n",
    "    'Falling on the left':0,\n",
    "    'Falling on knees':0,\n",
    "    'Falling on the back':0,\n",
    "    'Descending stairs':3,\n",
    "    'Standing':1,\n",
    "    'Lying down right':2,\n",
    "    'Walking at normal speed':3,\n",
    "    'Lying down on back':2,\n",
    "    'Desk work':1,\n",
    "    'Running':3,\n",
    "    'Climbing stairs':3,\n",
    "    'Falling on the right':0,\n",
    "    'Sitting bent backward':1,\n",
    "    'Sitting bent forward':1,\n",
    "    'Lying down left':2,\n",
    "    'Lying down on stomach':2,\n",
    "    'Sitting':1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64f39885-f401-4a80-94a6-2eba39c61d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = {\n",
    "    'Falling on the left':0,\n",
    "    'Falling on knees':1,\n",
    "    'Falling on the back':2,\n",
    "    'Descending stairs':3,\n",
    "    'Standing':4,\n",
    "    'Lying down right':5,\n",
    "    'Walking at normal speed':6,\n",
    "    'Lying down on back':7,\n",
    "    'Desk work':8,\n",
    "    'Running':9,\n",
    "    'Climbing stairs':10,\n",
    "    'Falling on the right':11,\n",
    "    'Sitting bent backward':12,\n",
    "    'Sitting bent forward':13,\n",
    "    'Lying down left':14,\n",
    "    'Lying down on stomach':16,\n",
    "    'Sitting':17\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff98bcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "falling_class_labels = {\n",
    "    0:0,\n",
    "    11:1,\n",
    "    2:2,\n",
    "    1:3\n",
    "}\n",
    "\n",
    "falling_class_labels_inv = {\n",
    "    0:0,\n",
    "    1:11,\n",
    "    2:2,\n",
    "    3:1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1fdc80a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sitting_standing_class_labels = {\n",
    "    13:0,\n",
    "    4:1,\n",
    "    17:2,\n",
    "    8:3,\n",
    "    12:4\n",
    "}\n",
    "\n",
    "sitting_standing_class_labels_inv = {\n",
    "    0:13,\n",
    "    1:4,\n",
    "    2:17,\n",
    "    3:8,\n",
    "    4:12\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da3813be",
   "metadata": {},
   "outputs": [],
   "source": [
    "lying_class_labels = {\n",
    "    16:0,\n",
    "    7:1,\n",
    "    14:2,\n",
    "    5:3\n",
    "}\n",
    "\n",
    "lying_class_labels_inv = {\n",
    "    0:16,\n",
    "    1:7,\n",
    "    2:14,\n",
    "    3:5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50c35e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_class_labels = {\n",
    "    10:0,\n",
    "    3:1,\n",
    "    6:2,\n",
    "    9:3\n",
    "}\n",
    "\n",
    "moving_class_labels_inv = {\n",
    "    0:10,\n",
    "    1:3,\n",
    "    2:6,\n",
    "    3:9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42d67295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1163900"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_sliding_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6433a3f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3fb4e016-9ffc-426d-a220-a253c38c7769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select five partitions and train the model on them\n",
    "random_partitions = [4, 16, 27, 31, 40] # 16 corresponds to the partition that excludes Kai's data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f39d05db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the training and testing features\n",
    "feature_lists_train = []\n",
    "feature_lists_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb670599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.57it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.53it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.54it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.67it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.63it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.60it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.46it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.30it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.26it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.29it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.52it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.54it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.53it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.49it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.52it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.31it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.63it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.63it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.64it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.18it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.19it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.52it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.48it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.42it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.49it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:03<00:00, 10.27it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in random_partitions:\n",
    "    print(i)\n",
    "    # now extract all features\n",
    "    feature_list = []\n",
    "\n",
    "    for col in columns_of_interest:\n",
    "        new_features = tsfresh.extract_features(timeseries_container=training_partitions[i], column_id='window_id',\n",
    "                            column_value=col, default_fc_parameters=tsfresh.feature_extraction.MinimalFCParameters(), n_jobs=8)\n",
    "        feature_list.append(new_features)\n",
    "\n",
    "    feature_list = pd.concat(feature_list, axis=1)\n",
    "    \n",
    "    feature_lists_train.append(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75d7c0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 40/40 [00:00<00:00, 343.15it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:00<00:00, 357.34it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:00<00:00, 391.94it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:00<00:00, 395.60it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:00<00:00, 362.48it/s]\n",
      "Feature Extraction: 100%|██████████| 40/40 [00:00<00:00, 375.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction: 100%|██████████| 39/39 [00:00<00:00, 330.61it/s]\n",
      "Feature Extraction: 100%|██████████| 39/39 [00:00<00:00, 302.31it/s]\n",
      "Feature Extraction: 100%|██████████| 39/39 [00:00<00:00, 321.50it/s]\n",
      "Feature Extraction: 100%|██████████| 39/39 [00:00<00:00, 308.87it/s]\n",
      "Feature Extraction: 100%|██████████| 39/39 [00:00<00:00, 306.18it/s]\n",
      "Feature Extraction: 100%|██████████| 39/39 [00:00<00:00, 295.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 37/37 [00:00<00:00, 367.57it/s]\n",
      "Feature Extraction: 100%|██████████| 37/37 [00:00<00:00, 398.62it/s]\n",
      "Feature Extraction: 100%|██████████| 37/37 [00:00<00:00, 343.29it/s]\n",
      "Feature Extraction: 100%|██████████| 37/37 [00:00<00:00, 353.61it/s]\n",
      "Feature Extraction: 100%|██████████| 37/37 [00:00<00:00, 366.65it/s]\n",
      "Feature Extraction: 100%|██████████| 37/37 [00:00<00:00, 350.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction: 100%|██████████| 39/39 [00:00<00:00, 392.17it/s]\n",
      "Feature Extraction: 100%|██████████| 39/39 [00:00<00:00, 428.52it/s]\n",
      "Feature Extraction: 100%|██████████| 39/39 [00:00<00:00, 396.19it/s]\n",
      "Feature Extraction: 100%|██████████| 39/39 [00:00<00:00, 413.95it/s]\n",
      "Feature Extraction: 100%|██████████| 39/39 [00:00<00:00, 432.59it/s]\n",
      "Feature Extraction: 100%|██████████| 39/39 [00:00<00:00, 402.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Extraction: 100%|██████████| 38/38 [00:00<00:00, 409.29it/s]\n",
      "Feature Extraction: 100%|██████████| 38/38 [00:00<00:00, 399.86it/s]\n",
      "Feature Extraction: 100%|██████████| 38/38 [00:00<00:00, 407.85it/s]\n",
      "Feature Extraction: 100%|██████████| 38/38 [00:00<00:00, 392.60it/s]\n",
      "Feature Extraction: 100%|██████████| 38/38 [00:00<00:00, 406.07it/s]\n",
      "Feature Extraction: 100%|██████████| 38/38 [00:00<00:00, 381.19it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in random_partitions:\n",
    "    print(i)\n",
    "    # now extract all features\n",
    "    feature_list = []\n",
    "\n",
    "    for col in columns_of_interest:\n",
    "        new_features = tsfresh.extract_features(timeseries_container=testing_partitions[i], column_id='window_id',\n",
    "                            column_value=col, default_fc_parameters=tsfresh.feature_extraction.MinimalFCParameters(), n_jobs=8)\n",
    "        feature_list.append(new_features)\n",
    "\n",
    "    feature_list = pd.concat(feature_list, axis=1)\n",
    "    \n",
    "    feature_lists_test.append(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca176369-da29-4714-99e6-56e673a5b0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filters = 64\n",
    "kernel_size = 3\n",
    "n_features = 6\n",
    "activation='relu'\n",
    "n_classes = 4\n",
    "window_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7bb2c7fb-f0fd-4d8a-9c24-71e62813a134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape = (22699, 50, 6)\n",
      "y train shape = (22699,)\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "y_train_reduced = []\n",
    "\n",
    "for window_id, group in training_partitions[16].groupby('window_id'): # use partition 16 so that Kai's data is excluded from training set\n",
    "    # print(f\"window_id = {window_id}\")\n",
    "    shape = group[columns_of_interest].values.shape\n",
    "    # print(f\"shape = {shape}\")    \n",
    "    X_train.append(group[columns_of_interest].values)\n",
    "    y_train.append(class_labels[group[\"activity_type\"].values[0]])\n",
    "    y_train_reduced.append(reduced_class_labels[group[\"activity_type\"].values[0]])\n",
    "    \n",
    "X_train = np.asarray(X_train)\n",
    "y_train = np.asarray(y_train)\n",
    "y_train_reduced = np.asarray(y_train_reduced)\n",
    "\n",
    "print(f\"X train shape = {X_train.shape}\")\n",
    "print(f\"y train shape = {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "005723c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "falling_indices = [j for j in range(len(y_train)) if (y_train[j]==0 or y_train[j]==1 or y_train[j]==2 or y_train[j]==11)]\n",
    "X_train_falling  = np.asarray([X_train[j] for j in falling_indices])\n",
    "y_train_falling = np.asarray([y_train[j] for j in falling_indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75c739c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sitting_standing_indices = [j for j in range(len(y_train)) if (y_train[j]==4 or y_train[j]==8 or y_train[j]==12 or y_train[j]==13 or y_train[j]==17)]\n",
    "X_train_sitting_standing = np.asarray([X_train[j] for j in sitting_standing_indices])\n",
    "y_train_sitting_standing = np.asarray([y_train[j] for j in sitting_standing_indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7006dafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lying_indices = [j for j in range(len(y_train)) if (y_train[j]==5 or y_train[j]==7 or y_train[j]==14 or y_train[j]==16)]\n",
    "X_train_lying = np.asarray([X_train[j] for j in lying_indices])\n",
    "y_train_lying = np.asarray([y_train[j] for j in lying_indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6013a05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_indices = [j for j in range(len(y_train)) if (y_train[j]==3 or y_train[j]==6 or y_train[j]==9 or y_train[j]==10 or y_train[j]==15)]\n",
    "X_train_moving = np.asarray([X_train[j] for j in moving_indices])\n",
    "y_train_moving = np.asarray([y_train[j] for j in moving_indices])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b6b7d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4361\n",
      "5924\n",
      "5231\n",
      "7183\n"
     ]
    }
   ],
   "source": [
    "print(len(falling_indices))\n",
    "print(len(sitting_standing_indices))\n",
    "print(len(lying_indices))\n",
    "print(len(moving_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b3c7a4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e295bb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_falling = np.asarray([falling_class_labels[y_train_falling[j]] for j in range(len(y_train_falling))])\n",
    "\n",
    "y_train_sitting_standing = np.asarray([sitting_standing_class_labels[y_train_sitting_standing[j]] for j in range(len(y_train_sitting_standing))])\n",
    "\n",
    "y_train_lying = np.asarray([lying_class_labels[y_train_lying[j]] for j in range(len(y_train_lying))])\n",
    "\n",
    "y_train_moving = np.asarray([moving_class_labels[y_train_moving[j]] for j in range(len(y_train_moving))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db6e0d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X test shape = (431, 50, 6)\n",
      "y test shape = (431,)\n"
     ]
    }
   ],
   "source": [
    "# Use Kai's data for testing\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "y_test_reduced = []\n",
    "\n",
    "\n",
    "for window_id, group in Kai_final_sliding_windows.groupby('window_id'):\n",
    "    # print(f\"window_id = {window_id}\")\n",
    "    shape = group[columns_of_interest].values.shape\n",
    "    # print(f\"shape = {shape}\")    \n",
    "    X_test.append(group[columns_of_interest].values)\n",
    "    y_test.append(class_labels[group[\"activity_type\"].values[0]])\n",
    "    y_test_reduced.append(reduced_class_labels[group[\"activity_type\"].values[0]])\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "y_test_reduced = np.array(y_test_reduced)\n",
    "\n",
    "print(f\"X test shape = {X_test.shape}\")\n",
    "print(f\"y test shape = {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "551f0de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d (ConvLSTM2D)    (None, 1, 23, 64)         54016     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 23, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1472)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               147300    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 404       \n",
      "=================================================================\n",
      "Total params: 201,720\n",
      "Trainable params: 201,720\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# reshape into subsequences (samples, time steps, rows, cols, channels)\n",
    "n_steps, n_length = 2, 25\n",
    "X_train = X_train.reshape((X_train.shape[0], n_steps, 1, n_length, n_features))\n",
    "X_test = X_test.reshape((X_test.shape[0], n_steps, 1, n_length, n_features))\n",
    "\n",
    "# the ConvLSTM Network Model for the top hierarchy\n",
    "\n",
    "model = Sequential()\n",
    "model.add(ConvLSTM2D(filters=64, kernel_size=(1,3), activation='relu', input_shape=(n_steps, 1, n_length, n_features)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19a05d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ae6b6e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OHE(num, n_classes):\n",
    "    return ([0 for x in range(num)] + [1] + [0 for x in range(n_classes - num - 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b25b05c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_OHE(l, n_classes):\n",
    "    return ([OHE(x, n_classes) for x in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f0aac77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_reduced = get_OHE(y_train_reduced, n_classes) # get one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "55a27b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_reduced = np.asarray(y_train_reduced, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3150fca5-3d06-4ba1-a1af-0799cb4cb837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape = (22699, 2, 1, 25, 6)\n",
      "y_train shape = (22699, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train shape = {X_train.shape}\")\n",
    "print(f\"y_train shape = {y_train_reduced.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "61bced60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "178/178 [==============================] - 21s 105ms/step - loss: 0.9075 - accuracy: 0.6809\n",
      "Epoch 2/5\n",
      "178/178 [==============================] - 11s 63ms/step - loss: 0.0856 - accuracy: 0.9751\n",
      "Epoch 3/5\n",
      "178/178 [==============================] - 11s 62ms/step - loss: 0.0559 - accuracy: 0.9827\n",
      "Epoch 4/5\n",
      "178/178 [==============================] - 22s 121ms/step - loss: 0.0411 - accuracy: 0.9866\n",
      "Epoch 5/5\n",
      "178/178 [==============================] - 26s 145ms/step - loss: 0.0386 - accuracy: 0.9883\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8c1a235eb0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit networkf or top layer\n",
    "model.fit(X_train, y_train_reduced, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eacc0541-4cc2-4518-b3ff-9446c9f2f344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(431,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stats\n",
    "y_pred_ohe = model.predict(X_test)\n",
    "y_pred_labels = np.argmax(y_pred_ohe, axis=1)\n",
    "y_pred_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "182a5e92-6adf-4030-9880-c1cb4e332f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test_reduced, y_pred_labels)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c46fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fallings = [X_train_falling for _ in range(5)]\n",
    "X_train_falling_concat = np.concatenate(X_train_fallings)\n",
    "y_train_fallings = [y_train_falling for _ in range(5)]\n",
    "y_train_falling_concat = np.concatenate(y_train_fallings)\n",
    "\n",
    "X_train_sitting_standings = [X_train_sitting_standing for _ in range(5)]\n",
    "X_train_sitting_standing_concat = np.concatenate(X_train_sitting_standings)\n",
    "y_train_sitting_standings = [y_train_sitting_standing for _ in range(5)]\n",
    "y_train_sitting_standing_concat = np.concatenate(y_train_sitting_standings)\n",
    "\n",
    "X_train_lyings = [X_train_lying for _ in range(5)]\n",
    "X_train_lying_concat = np.concatenate(X_train_lyings)\n",
    "y_train_lyings = [y_train_lying for _ in range(5)]\n",
    "y_train_lying_concat = np.concatenate(y_train_lyings)\n",
    "\n",
    "X_train_movings = [X_train_moving for _ in range(5)]\n",
    "X_train_moving_concat = np.concatenate(X_train_movings)\n",
    "y_train_movings = [y_train_moving for _ in range(5)]\n",
    "y_train_moving_concat = np.concatenate(y_train_movings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "21815b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_falling_indices = [j for j in range(len(y_pred_labels)) if (y_pred_labels[j]==0)]\n",
    "pred_sitting_standing_indices = [j for j in range(len(y_pred_labels)) if (y_pred_labels[j]==1)]\n",
    "pred_lying_indices = [j for j in range(len(y_pred_labels)) if (y_pred_labels[j]==2)]\n",
    "pred_moving_indices = [j for j in range(len(y_pred_labels)) if (y_pred_labels[j]==3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "caf99719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct the original labels\n",
    "y_pred_orig_labels = np.zeros(shape=(len(y_pred_labels),), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3b9bc75d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 2, 1, 25, 6)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pred_falling = np.array([X_test[j] for j in pred_falling_indices])\n",
    "X_pred_falling.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "be218657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145, 2, 1, 25, 6)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pred_sitting_standing = np.array([X_test[j] for j in pred_sitting_standing_indices])\n",
    "X_pred_sitting_standing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "28ee3d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116, 2, 1, 25, 6)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pred_lying = np.array([X_test[j] for j in pred_lying_indices])\n",
    "X_pred_lying.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "17a60ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116, 2, 1, 25, 6)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pred_moving = np.array([X_test[j] for j in pred_moving_indices])\n",
    "X_pred_moving.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c6f0a6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# develop model for distinguishing lying types\n",
    "\n",
    "def predict_lying_category(X_test):\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1]*X_test.shape[2]*X_test.shape[3], X_test.shape[4])\n",
    "    X_test_means = np.mean(X_test, axis=1)\n",
    "    y_pred = np.zeros(shape=(X_test.shape[0],), dtype=int)\n",
    "    for i in range(X_test_means.shape[0]):\n",
    "        accel_x, accel_y, accel_z = X_test_means[i][0], X_test_means[i][1], X_test_means[i][2]\n",
    "        accel_norm = np.sqrt(accel_x**2 + accel_y**2 + accel_z**2)\n",
    "        cos_theta_z = accel_z/accel_norm\n",
    "        theta_z = np.arccos(cos_theta_z) * 180/np.pi # get angle in degrees\n",
    "        if theta_z >= 0.0 and theta_z <= 45.0:\n",
    "            y_pred[i] = 1 # on back\n",
    "        elif theta_z > 45.0 and theta_z <= 90.0:\n",
    "            y_pred[i] = 3 # on right\n",
    "        elif theta_z > 90.0 and theta_z <= 135.0:\n",
    "            y_pred[i] = 2 # on left\n",
    "        elif theta_z > 135.0 and theta_z <= 180.0:\n",
    "            y_pred[i] = 0 # on stomach\n",
    "        else:\n",
    "            y_pred[i] = 1 # default is on back\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a8481c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lying_labels = predict_lying_category(X_pred_lying)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e6fd48ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels back to original\n",
    "y_pred_lying_orig_labels = [lying_class_labels_inv[y_pred_lying_labels[j]] for j in range(len(y_pred_lying_labels))]\n",
    "for j in range(len(y_pred_lying_labels)):\n",
    "    y_pred_orig_labels[pred_lying_indices[j]] = y_pred_lying_orig_labels[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6e05b0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_falling_model(n_classes=4, X_train_falling=X_train_falling_concat, y_train_falling=y_train_falling_concat):\n",
    "    # reshape into subsequences (samples, time steps, rows, cols, channels)\n",
    "    n_steps, n_length = 2, 25\n",
    "    X_train_falling = X_train_falling.reshape((X_train_falling.shape[0], n_steps, 1, n_length, n_features))\n",
    "    \n",
    "    # the ConvLSTM Network Model for the 'falling' class\n",
    "    falling_model = Sequential()\n",
    "    falling_model.add(ConvLSTM2D(filters=64, kernel_size=(1,3), activation='relu', input_shape=(n_steps, 1, n_length, n_features)))\n",
    "    falling_model.add(Dropout(0.5))\n",
    "    falling_model.add(Flatten())\n",
    "    falling_model.add(Dense(100, activation='relu'))\n",
    "    falling_model.add(Dense(n_classes, activation='softmax'))\n",
    "    falling_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    y_train_falling = np.asarray(get_OHE(y_train_falling, n_classes), dtype=np.float32)\n",
    "    \n",
    "    falling_model.fit(X_train_falling, y_train_falling, epochs=5, batch_size=64)\n",
    "    return falling_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9ae56969",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "341/341 [==============================] - 11s 27ms/step - loss: 0.5592 - accuracy: 0.8829\n",
      "Epoch 2/5\n",
      "341/341 [==============================] - 14s 40ms/step - loss: 0.0103 - accuracy: 0.9974\n",
      "Epoch 3/5\n",
      "341/341 [==============================] - 28s 83ms/step - loss: 0.0036 - accuracy: 0.9991\n",
      "Epoch 4/5\n",
      "341/341 [==============================] - 20s 60ms/step - loss: 0.0032 - accuracy: 0.9989\n",
      "Epoch 5/5\n",
      "341/341 [==============================] - 9s 26ms/step - loss: 0.0039 - accuracy: 0.9988\n"
     ]
    }
   ],
   "source": [
    "falling_model = setup_falling_model()\n",
    "\n",
    "if len(X_pred_falling != 0):\n",
    "    y_pred_falling_ohe = falling_model.predict(X_pred_falling)\n",
    "    y_pred_falling_labels = np.argmax(y_pred_falling_ohe, axis=1)\n",
    "    # convert labels back to original\n",
    "    y_pred_falling_orig_labels = [falling_class_labels_inv[y_pred_falling_labels[j]] for j in range(len(y_pred_falling_labels))]\n",
    "    # print(np.asarray(y_pred_falling_orig_labels))\n",
    "    for j in range(len(y_pred_falling_labels)):\n",
    "        y_pred_orig_labels[pred_falling_indices[j]] = y_pred_falling_orig_labels[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "37dac866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "       14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "        7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "        7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7, 16, 16, 16, 16, 16,\n",
       "       16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "       16, 16, 16, 16, 16, 16, 16,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_orig_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6542ee34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "       10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,  3,  3,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "        3,  3,  3,  3,  3,  3,  3,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "        8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "        8,  8,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  2,  2,\n",
       "        2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
       "       11, 11, 11, 11, 11, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "       14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "        7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "        7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7, 16, 16, 16, 16, 16,\n",
       "       16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "       16, 16, 16, 16, 16, 16, 16,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "        5,  5,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "        9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 12, 12, 12,\n",
       "       12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "       12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "       13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "       13, 13, 13, 13, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "       17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,  4,\n",
       "        4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "        4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacadfc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
